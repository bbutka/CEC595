{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of L14qs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bbutka/CEC595/blob/main/07a_3qs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kilKsIChiW0G"
      },
      "source": [
        "What do you think would happen if we used nearest neighbors (or naive Bayes or a neural network) classifier on the raw vectors?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0wL-7mKuLue"
      },
      "source": [
        "We'll download addtional images from GitHub below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIFeQY9hOVl9",
        "outputId": "fafe134a-1871-4920-c060-ef1f80d9f769",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1e7WmmVCF9ByOdEkqO0-ft3OWJoD7XHdU' -O IMAGES.zip\r\n",
        "!unzip IMAGES.zip "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-03 17:56:35--  https://docs.google.com/uc?export=download&id=1e7WmmVCF9ByOdEkqO0-ft3OWJoD7XHdU\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.112.102, 108.177.112.100, 108.177.112.101, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.112.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0s-2c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/qd6cuj8refkg18ekjbpqgp598ru5b34l/1614794175000/08914542393121785554/*/1e7WmmVCF9ByOdEkqO0-ft3OWJoD7XHdU?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2021-03-03 17:56:36--  https://doc-0s-2c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/qd6cuj8refkg18ekjbpqgp598ru5b34l/1614794175000/08914542393121785554/*/1e7WmmVCF9ByOdEkqO0-ft3OWJoD7XHdU?e=download\n",
            "Resolving doc-0s-2c-docs.googleusercontent.com (doc-0s-2c-docs.googleusercontent.com)... 74.125.129.132, 2607:f8b0:4001:c15::84\n",
            "Connecting to doc-0s-2c-docs.googleusercontent.com (doc-0s-2c-docs.googleusercontent.com)|74.125.129.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-zip-compressed]\n",
            "Saving to: ‘IMAGES.zip’\n",
            "\n",
            "IMAGES.zip              [ <=>                ]   6.51M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2021-03-03 17:56:37 (72.0 MB/s) - ‘IMAGES.zip’ saved [6830866]\n",
            "\n",
            "Archive:  IMAGES.zip\n",
            "  inflating: A1.jpg                  \n",
            " extracting: A10.jpg                 \n",
            "  inflating: A2.jpg                  \n",
            " extracting: A3.jpg                  \n",
            "  inflating: A4.jpg                  \n",
            "  inflating: A5.jpg                  \n",
            "  inflating: A6.jpg                  \n",
            "  inflating: A7.jpg                  \n",
            "  inflating: A8.jpg                  \n",
            " extracting: A9.jpg                  \n",
            " extracting: N1.jpg                  \n",
            " extracting: N10.jpg                 \n",
            "  inflating: N2.jpg                  \n",
            "  inflating: N3.jpg                  \n",
            "  inflating: N4.jpg                  \n",
            " extracting: N5.jpg                  \n",
            " extracting: N6.jpg                  \n",
            "  inflating: N7.jpg                  \n",
            "  inflating: N8.jpg                  \n",
            "  inflating: N9.jpg                  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIvRfL5QaTrv"
      },
      "source": [
        "Loading the raw image vectors as a dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ1GesmY9mDf"
      },
      "source": [
        "# get images\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import numpy as np\n",
        "         \n",
        "dat = []\n",
        "labs = []\n",
        "imgs = []\n",
        "imgflist = [\"A1\", \"A2\", \"A3\", \"A4\", \"A5\", \"A6\", \"A7\", \"A8\", \"A9\", \"A10\",\n",
        "           \"N1\", \"N2\", \"N3\", \"N4\", \"N5\", \"N6\", \"N7\", \"N8\", \"N9\", \"N10\"]\n",
        "for imgf in imgflist:\n",
        "    img = image.load_img(imgf+\".jpg\", target_size=(224,224))\n",
        "    imgs.append(img)\n",
        "    img_arr = np.expand_dims(image.img_to_array(img), axis=0)\n",
        "#    x = preprocess_input(img_arr)\n",
        "#    preds = model2.predict(x)\n",
        "    dat.append(img_arr.flatten())\n",
        "    labs.append(imgf[0:2] == 'ff')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj_J81yTbiwc"
      },
      "source": [
        "Dividing the data into training and testing data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4plqRVQrdWIQ"
      },
      "source": [
        "train = [i for i in range(0,5)]+[i for i in range(10,15)]\n",
        "test = [i for i in range(5,10)]+[i for i in range(15,20)]\n",
        "\n",
        "X_train = [dat[inst] for inst in train]\n",
        "y_train = [labs[inst] for inst in train]\n",
        "X_test =  [dat[inst] for inst in test]\n",
        "y_test =  [labs[inst] for inst in test]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nL0qTNbHihsq"
      },
      "source": [
        "Train using Naive Bayes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_rkqAnbdcLm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dbde8ab-c302-438e-a5d2-0ba627a32b47"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "score = clf.score(X_test, y_test)\n",
        "\n",
        "print(score)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afJ7zkhrij1a"
      },
      "source": [
        "Train using nearest neighbor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD7MzdFcdiAt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71916b99-2453-4364-831d-7f29a4f4a431"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "clf = KNeighborsClassifier(n_neighbors=1,metric=\"cosine\")\n",
        "clf.fit(X_train, y_train)\n",
        "score = clf.score(X_test, y_test)\n",
        "\n",
        "print(score)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa09vQuVimj8"
      },
      "source": [
        "Train using neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz95vOMDfN8U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4898edb0-27b5-4777-9a14-4c7e898e47bf"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "clf = MLPClassifier(hidden_layer_sizes=[100, 100, 100, 100, 100], max_iter = 10000)\n",
        "clf.fit(X_train, y_train)\n",
        "score = clf.score(X_test, y_test)\n",
        "\n",
        "print(score)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5fVZ_TlggDT"
      },
      "source": [
        "For comparison, here are those same algorithms using the representation that comes from VGG16."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9acgp2_ftSf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fed61d90-6b3e-41c9-cb90-0e9c61640760"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Dense,Flatten\n",
        "from keras.applications import vgg16\n",
        "from keras import backend as K\n",
        "\n",
        "model = vgg16.VGG16(weights='imagenet', include_top=True)\n",
        "\n",
        "model2 = Model(model.input, model.layers[-2].output)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIko-YKGiH-s"
      },
      "source": [
        "Gather the vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMdt2G2Agy-K"
      },
      "source": [
        "datraw = dat\n",
        "dat = []\n",
        "\n",
        "for img in imgs:\n",
        "    img_arr = np.expand_dims(image.img_to_array(img), axis=0)\n",
        "    x = preprocess_input(img_arr)\n",
        "    preds = model2.predict(x)\n",
        "    dat.append(preds[0])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ3wimixiKY-"
      },
      "source": [
        "Make a new training/testing set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dgwO3Wwho1C"
      },
      "source": [
        "train = [i for i in range(0,5)]+[i for i in range(10,15)]\n",
        "test = [i for i in range(5,10)]+[i for i in range(15,20)]\n",
        "\n",
        "X_train = [dat[inst] for inst in train]\n",
        "y_train = [labs[inst] for inst in train]\n",
        "X_test =  [dat[inst] for inst in test]\n",
        "y_test =  [labs[inst] for inst in test]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvWe0V_piM-7",
        "outputId": "f9897fdc-e57b-48b4-f85b-abfb86088039",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "Naive Bayes."
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-d0b9497c4c2d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Naive Bayes.\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xY3KmE9ThOZu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59a7471c-4107-41c2-e7b7-ed6ee996af01"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "score = clf.score(X_test, y_test)\n",
        "\n",
        "print(score)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9om5O0fYiPF8"
      },
      "source": [
        "Nearest neighbors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sO7EQGrhSdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "009f3e94-e16e-4db2-9b20-9a3f44f30b44"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "clf = KNeighborsClassifier(n_neighbors=1,metric=\"cosine\")\n",
        "clf.fit(X_train, y_train)\n",
        "score = clf.score(X_test, y_test)\n",
        "\n",
        "print(score)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETy5W-4diRoB"
      },
      "source": [
        "And neural networks, all perfect."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCysBL8HhUel",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "399a03c1-7c05-4a2f-a6d9-66f57a81d5d2"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "clf = MLPClassifier(hidden_layer_sizes=[100, 100, 100, 100, 100], max_iter = 10000)\n",
        "clf.fit(X_train, y_train)\n",
        "score = clf.score(X_test, y_test)\n",
        "\n",
        "print(score)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}