{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of L14qs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bbutka/CEC595/blob/main/7a_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kilKsIChiW0G"
      },
      "source": [
        "We showed that the VGG-16 network can be used to encode images it was not trained on---a cheese grater and a foot file---as vectors that are perfectly recognized by K nearest neighbors. What do you think would happen if we used nearest neighbors (or naive Bayes or a neural network) classifier on the raw vectors?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0wL-7mKuLue"
      },
      "source": [
        "We'll download addtional images from GitHub below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XdXSJxHvOBP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d7d84e0-941c-40da-9f67-e2e78f2160e2"
      },
      "source": [
        "!wget https://github.com/mlittmancs/great_courses_ml/raw/master/imgs/tools.zip\n",
        "!unzip tools.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-03 17:49:51--  https://github.com/mlittmancs/great_courses_ml/raw/master/imgs/tools.zip\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/mlittmancs/great_courses_ml/master/imgs/tools.zip [following]\n",
            "--2021-03-03 17:49:51--  https://raw.githubusercontent.com/mlittmancs/great_courses_ml/master/imgs/tools.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2502460 (2.4M) [application/zip]\n",
            "Saving to: ‘tools.zip’\n",
            "\n",
            "tools.zip           100%[===================>]   2.39M  12.7MB/s    in 0.2s    \n",
            "\n",
            "2021-03-03 17:49:51 (12.7 MB/s) - ‘tools.zip’ saved [2502460/2502460]\n",
            "\n",
            "Archive:  tools.zip\n",
            "  inflating: cg01.jpeg               \n",
            "  inflating: cg02.jpeg               \n",
            "  inflating: cg03.jpeg               \n",
            "  inflating: cg04.jpeg               \n",
            "  inflating: cg05.jpeg               \n",
            "  inflating: cg06.jpeg               \n",
            "  inflating: cg07.jpeg               \n",
            "  inflating: cg08.jpeg               \n",
            "  inflating: cg09.jpeg               \n",
            "  inflating: cg10.jpeg               \n",
            "  inflating: ff01.jpeg               \n",
            "  inflating: ff02.jpeg               \n",
            "  inflating: ff03.jpeg               \n",
            "  inflating: ff04.jpeg               \n",
            "  inflating: ff05.jpeg               \n",
            "  inflating: ff06.jpeg               \n",
            "  inflating: ff07.jpeg               \n",
            "  inflating: ff08.jpeg               \n",
            "  inflating: ff09.jpeg               \n",
            "  inflating: ff10.jpeg               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIvRfL5QaTrv"
      },
      "source": [
        "Loading the raw image vectors as a dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ1GesmY9mDf"
      },
      "source": [
        "# get images\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import numpy as np\n",
        "         \n",
        "dat = []\n",
        "labs = []\n",
        "imgs = []\n",
        "imgflist = [\"cg01\", \"cg02\", \"cg03\", \"cg04\", \"cg05\", \"cg06\", \"cg07\", \"cg08\", \"cg09\", \"cg10\",\n",
        "           \"ff01\", \"ff02\", \"ff03\", \"ff04\", \"ff05\", \"ff06\", \"ff07\", \"ff08\", \"ff09\", \"ff10\"]\n",
        "for imgf in imgflist:\n",
        "    img = image.load_img(imgf+\".jpeg\", target_size=(224,224))\n",
        "    imgs.append(img)\n",
        "    img_arr = np.expand_dims(image.img_to_array(img), axis=0)\n",
        "#    x = preprocess_input(img_arr)\n",
        "#    preds = model2.predict(x)\n",
        "    dat.append(img_arr.flatten())\n",
        "    labs.append(imgf[0:2] == 'ff')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj_J81yTbiwc"
      },
      "source": [
        "Dividing the data into training and testing data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4plqRVQrdWIQ"
      },
      "source": [
        "train = [i for i in range(0,5)]+[i for i in range(10,15)]\n",
        "test = [i for i in range(5,10)]+[i for i in range(15,20)]\n",
        "\n",
        "X_train = [dat[inst] for inst in train]\n",
        "y_train = [labs[inst] for inst in train]\n",
        "X_test =  [dat[inst] for inst in test]\n",
        "y_test =  [labs[inst] for inst in test]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nL0qTNbHihsq"
      },
      "source": [
        "Train using Naive Bayes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_rkqAnbdcLm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "536c8ddf-3cec-465d-e4f2-405d0fb2327e"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "score = clf.score(X_test, y_test)\n",
        "\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afJ7zkhrij1a"
      },
      "source": [
        "Train using nearest neighbor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD7MzdFcdiAt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f350dbba-cdd1-45c2-89a7-a71e7c2e4f8c"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "clf = KNeighborsClassifier(n_neighbors=1,metric=\"cosine\")\n",
        "clf.fit(X_train, y_train)\n",
        "score = clf.score(X_test, y_test)\n",
        "\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa09vQuVimj8"
      },
      "source": [
        "Train using neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz95vOMDfN8U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "72ab3212-6dd9-440e-a39b-54ff777b2872"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "clf = MLPClassifier(hidden_layer_sizes=[100, 100, 100, 100, 100], max_iter = 10000)\n",
        "clf.fit(X_train, y_train)\n",
        "score = clf.score(X_test, y_test)\n",
        "\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5fVZ_TlggDT"
      },
      "source": [
        "For comparison, here are those same algorithms using the representation that comes from VGG16."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9acgp2_ftSf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "d1313e54-8cc1-45b7-b9f7-01bc605211ef"
      },
      "source": [
        "!pip install keras=='2.3.1'\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense,Flatten\n",
        "from keras.applications import vgg16\n",
        "from keras import backend as K\n",
        "\n",
        "model = vgg16.VGG16(weights='imagenet', include_top=True)\n",
        "\n",
        "model2 = Model(model.input, model.layers[-2].output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras==2.3.1 in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (2.10.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.18.5)\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIko-YKGiH-s"
      },
      "source": [
        "Gather the vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMdt2G2Agy-K"
      },
      "source": [
        "datraw = dat\n",
        "dat = []\n",
        "\n",
        "for img in imgs:\n",
        "    img_arr = np.expand_dims(image.img_to_array(img), axis=0)\n",
        "    x = preprocess_input(img_arr)\n",
        "    preds = model2.predict(x)\n",
        "    dat.append(preds[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ3wimixiKY-"
      },
      "source": [
        "Make a new training/testing set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dgwO3Wwho1C"
      },
      "source": [
        "train = [i for i in range(0,5)]+[i for i in range(10,15)]\n",
        "test = [i for i in range(5,10)]+[i for i in range(15,20)]\n",
        "\n",
        "X_train = [dat[inst] for inst in train]\n",
        "y_train = [labs[inst] for inst in train]\n",
        "X_test =  [dat[inst] for inst in test]\n",
        "y_test =  [labs[inst] for inst in test]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvWe0V_piM-7"
      },
      "source": [
        "Naive Bayes."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xY3KmE9ThOZu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "10183b22-6c7a-42a2-d128-816f773c8bbf"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "score = clf.score(X_test, y_test)\n",
        "\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9om5O0fYiPF8"
      },
      "source": [
        "Nearest neighbors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sO7EQGrhSdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e8c59b0a-535b-44f3-d727-47008a3118a1"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "clf = KNeighborsClassifier(n_neighbors=1,metric=\"cosine\")\n",
        "clf.fit(X_train, y_train)\n",
        "score = clf.score(X_test, y_test)\n",
        "\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETy5W-4diRoB"
      },
      "source": [
        "And neural networks, all perfect."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCysBL8HhUel",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc07fdef-152b-4397-e818-aa342c78dbe9"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "clf = MLPClassifier(hidden_layer_sizes=[100, 100, 100, 100, 100], max_iter = 10000)\n",
        "clf.fit(X_train, y_train)\n",
        "score = clf.score(X_test, y_test)\n",
        "\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}