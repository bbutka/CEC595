{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "L5a_Pitfalls.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bbutka/CEC595/blob/main/L05a_Pitfalls.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHh0_yrIPgCw"
      },
      "source": [
        "In this notebook we will train a multi-layer perceptron and a logistic regression on our ship data\n",
        "\n",
        "We load our libraries below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kx6zoLVxPmax"
      },
      "source": [
        "import csv\n",
        "import random\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSa0KFHRPz3M"
      },
      "source": [
        "Below we download our ship data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7dokpKs6hnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40837992-60d8-49fb-d0a2-70b830a80c82"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/bbutka/CEC595/main/data/ship.csv"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-09 19:13:19--  https://raw.githubusercontent.com/bbutka/CEC595/main/data/ship.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 61194 (60K) [text/plain]\n",
            "Saving to: ‘ship.csv’\n",
            "\n",
            "ship.csv            100%[===================>]  59.76K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2021-01-09 19:13:19 (4.32 MB/s) - ‘ship.csv’ saved [61194/61194]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wstPtP6MP2f3"
      },
      "source": [
        "Next, we write a script to process the data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSKpcO_GAwEX"
      },
      "source": [
        "first = True\n",
        "with open(\"ship.csv\") as f:\n",
        "    csvdata = csv.reader(f, delimiter=',')\n",
        "    data = []\n",
        "    for row in csvdata:\n",
        "      if not first: data += [row]\n",
        "      first = False\n",
        "\n",
        "array = []\n",
        "for col in range(len(data[0])):\n",
        "  array += [{}]\n",
        "  new = 0\n",
        "  for i in range(len(data)):\t\n",
        "     line = data[i]\t\t\n",
        "     if line[col] not in array[col]:\n",
        "      array[col][line[col]] = new\n",
        "      new += 1  \n",
        "alldat = []\n",
        "alllabs = []\n",
        "for line in data:\n",
        "  alllabs += [int(line[1])]\n",
        "  if line[5] == '': line[5] = '50'\n",
        "  alldat += [ [int(line[2]), array[4][line[4]], float(line[5]), int(line[6]), int(line[7]), float(line[9]), line[11]=='S', line[11]=='C', line[11]=='Q' ]]\n",
        "feats = ['Pclass','Sex','Age','SibSp','Parch','Fare', 'Embarked S', 'Embarked C', 'Embarked Q']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoDHyFJqQOYG"
      },
      "source": [
        "With our data processed, we create a `trainmask` to randomly separate our training from test data.  We will use the mask to get the training and test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofqb0JywAwHq"
      },
      "source": [
        "trainmask = [random.randint(0,2) for i in range(len(alldat))]\n",
        "\n",
        "traindat = [alldat[i] for i in range(len(alldat)) if trainmask[i]<2]\n",
        "trainlabs = [alllabs[i] for i in range(len(alldat)) if trainmask[i]<2]\n",
        "testdat = [alldat[i] for i in range(len(alldat)) if trainmask[i]==2]\n",
        "testlabs = [alllabs[i] for i in range(len(alldat)) if trainmask[i]==2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdBwZXHVSQma"
      },
      "source": [
        "We next will train a multi-layer perceptron with 60 hidden units to classify the data and print the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3AB24vMAwKQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08ad05d0-e1ef-475a-9c4d-4846d95afc6a"
      },
      "source": [
        "nhidden = 60\n",
        "clf = MLPClassifier(hidden_layer_sizes=[nhidden], max_iter = 50000)\n",
        "clf = clf.fit(traindat, trainlabs)\n",
        "pred = clf.predict(testdat)\n",
        "[sum([pred[i] != testlabs[i] for i in range(len(testlabs))]) / len(testlabs)]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.19047619047619047]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcAt69OsUgtV"
      },
      "source": [
        "Next we will calculate how much higher the predictions are for females vs. males."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TksEEdN6AwNA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68ad6774-a6ac-455d-dce0-efcc48ae98cc"
      },
      "source": [
        "# feats = ['Pclass','Sex','Age','SibSp','Parch','Fare', 'Embarked S', 'Embarked C', 'Embarked Q']\n",
        "\n",
        "imp = []\n",
        "for v in alldat:\n",
        "  real = v[1]\n",
        "  v[1] = 0\n",
        "  asmale = clf.predict_proba([v])[0][1]\n",
        "  v[1] = 1\n",
        "  asfemale = clf.predict_proba([v])[0][1]\n",
        "  v[1] = real\n",
        "  imp += [ asfemale-asmale ]\n",
        "  \n",
        "print(sum(imp)/len(imp))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4230867162154019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRBZGqvJa9Y9"
      },
      "source": [
        "Next we will train a logistic regression and print the accuracy of the model on the train and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hc9aJadgAwPe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0aaa1cff-d577-45ab-eecd-1b9b5d3f1ac4"
      },
      "source": [
        "clf = LogisticRegression(max_iter = 500)\n",
        "\n",
        "clf.fit(traindat, trainlabs)  \n",
        "\n",
        "pred = clf.predict(traindat)\n",
        "trainerr = sum([pred[i] != trainlabs[i] for i in range(len(trainlabs))]) / len(trainlabs)\n",
        "pred = clf.predict(testdat)\n",
        "testerr = sum([pred[i] != testlabs[i] for i in range(len(testlabs))]) / len(testlabs)\n",
        "\n",
        "print(trainerr, testerr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2152777777777778 0.17777777777777778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTSfeqQnbLYR"
      },
      "source": [
        "Finally we'll plot the coefficients of the logistic regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYh53kOFAwSK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "046ddf3f-ca1a-4dbb-bd01-d01f18ff53eb"
      },
      "source": [
        "for i in range(len(feats)):\n",
        "  print(feats[i], clf.coef_[0][i])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pclass -0.8591194432385889\n",
            "Sex 2.5902801936563105\n",
            "Age -0.02604913505612622\n",
            "SibSp -0.34447690011474924\n",
            "Parch -0.20977293343256473\n",
            "Fare 0.0022917046260743585\n",
            "Embarked S -0.3617682332239227\n",
            "Embarked C 0.04286405796040166\n",
            "Embarked Q 0.18103820238828897\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}