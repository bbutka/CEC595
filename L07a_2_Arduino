{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"L7a_2_Arduino","provenance":[{"file_id":"https://github.com/bbutka/ml/blob/master/L14.ipynb","timestamp":1609101800788}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"8WYu7l8dRtQ-"},"source":["This notebook uses a deep learning image classification model, VGG16, to find similar images among a set of photos of Arduinos\n","\n","Below we import the libraries we'll be using."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z2DFWnWNyqze","executionInfo":{"status":"ok","timestamp":1610048101490,"user_tz":300,"elapsed":3223,"user":{"displayName":"Brian Butka","photoUrl":"","userId":"08914542393121785554"}},"outputId":"8a0c160d-be5a-49d8-8cd7-454bf9d11474"},"source":["!pip install keras=='2.3.1'\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense,Flatten\n","from tensorflow.keras.applications import vgg16\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.applications.vgg16 import preprocess_input\n","import numpy as np "],"execution_count":13,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: keras==2.3.1 in /usr/local/lib/python3.6/dist-packages (2.3.1)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.19.4)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (3.13)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.0.8)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.1.2)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (2.10.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.4.1)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DNlMft7quA70"},"source":["We'll download the model VGG16 that has already been trained on the dataset ImageNet."]},{"cell_type":"code","metadata":{"id":"R6e0fdZ2yYBL","executionInfo":{"status":"ok","timestamp":1610048108303,"user_tz":300,"elapsed":4510,"user":{"displayName":"Brian Butka","photoUrl":"","userId":"08914542393121785554"}}},"source":["model = vgg16.VGG16(weights='imagenet', include_top=True)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y5i4lT8tURcT"},"source":["Next, we'll remove the last two layers of the model."]},{"cell_type":"code","metadata":{"id":"P-5cbD72zKnw","executionInfo":{"status":"ok","timestamp":1610048109654,"user_tz":300,"elapsed":709,"user":{"displayName":"Brian Butka","photoUrl":"","userId":"08914542393121785554"}}},"source":["model2 = Model(model.input, model.layers[-2].output)"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B0wL-7mKuLue"},"source":["We'll download addtional images from GitHub below"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q0nMtOxh7Lrx","executionInfo":{"status":"ok","timestamp":1610048122954,"user_tz":300,"elapsed":10990,"user":{"displayName":"Brian Butka","photoUrl":"","userId":"08914542393121785554"}},"outputId":"3f3e6aad-2b7f-43f0-f163-3fec253db14a"},"source":["!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1e7WmmVCF9ByOdEkqO0-ft3OWJoD7XHdU' -O IMAGES.zip\r\n","!unzip IMAGES.zip "],"execution_count":16,"outputs":[{"output_type":"stream","text":["--2021-01-07 19:35:12--  https://docs.google.com/uc?export=download&id=1e7WmmVCF9ByOdEkqO0-ft3OWJoD7XHdU\n","Resolving docs.google.com (docs.google.com)... 74.125.203.101, 74.125.203.139, 74.125.203.100, ...\n","Connecting to docs.google.com (docs.google.com)|74.125.203.101|:443... connected.\n","HTTP request sent, awaiting response... 302 Moved Temporarily\n","Location: https://doc-0s-2c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/tnvcq9227579qm9hkhe54muh4v8kiish/1610048100000/08914542393121785554/*/1e7WmmVCF9ByOdEkqO0-ft3OWJoD7XHdU?e=download [following]\n","Warning: wildcards not supported in HTTP.\n","--2021-01-07 19:35:13--  https://doc-0s-2c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/tnvcq9227579qm9hkhe54muh4v8kiish/1610048100000/08914542393121785554/*/1e7WmmVCF9ByOdEkqO0-ft3OWJoD7XHdU?e=download\n","Resolving doc-0s-2c-docs.googleusercontent.com (doc-0s-2c-docs.googleusercontent.com)... 74.125.23.132, 2404:6800:4008:c02::84\n","Connecting to doc-0s-2c-docs.googleusercontent.com (doc-0s-2c-docs.googleusercontent.com)|74.125.23.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [application/x-zip-compressed]\n","Saving to: ‘IMAGES.zip’\n","\n","IMAGES.zip              [ <=>                ]   6.51M  --.-KB/s    in 0.09s   \n","\n","2021-01-07 19:35:14 (74.2 MB/s) - ‘IMAGES.zip’ saved [6830866]\n","\n","Archive:  IMAGES.zip\n","replace A1.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8XdXSJxHvOBP"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"GIvRfL5QaTrv"},"source":["We will then load and process the images so that we can input them into our model and use the predictions from the model to find pairs of images that are most similar to each other according to our model."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1FryxY_Tplz3nhk-hCfx3p0TH2vMYuyO7"},"id":"bQ1GesmY9mDf","executionInfo":{"status":"ok","timestamp":1610048153490,"user_tz":300,"elapsed":28510,"user":{"displayName":"Brian Butka","photoUrl":"","userId":"08914542393121785554"}},"outputId":"0ac7a53a-4e8b-48ae-c04d-1ad0435a6d8d"},"source":["# get images\n","from PIL import Image\n","from IPython.display import display\n","         \n","dat = []\n","labs = []\n","imgs = []\n","imgflist = [\"A1\", \"A2\", \"A3\", \"A4\", \"A5\", \"A6\", \"A7\", \"A8\", \"A9\", \"A10\",\n","           \"N1\", \"N2\", \"N3\", \"N4\", \"N5\", \"N6\", \"N7\", \"N8\", \"N9\", \"N10\"]\n","for imgf in imgflist:\n","    img = image.load_img(imgf+\".jpg\", target_size=(224,224))\n","    imgs.append(img)\n","    img_arr = np.expand_dims(image.img_to_array(img), axis=0)\n","    x = preprocess_input(img_arr)\n","    preds = model2.predict(x)\n","    dat.append(preds[0])\n","for i in range(len(dat)):\n","  i1 = dat[i]\n","  bestmatch, bestsim = -1, 0\n","  for j in range(len(dat)):\n","    i2 = dat[j]\n","    sim = i1 @ i2   #Dot product\n","    if sim > bestsim and i != j: bestmatch, bestsim = j, sim\n","  print(i,bestmatch)\n","  display(imgs[i], imgs[bestmatch])"],"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}