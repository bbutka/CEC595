{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"L8a_text.ipynb","provenance":[{"file_id":"https://github.com/bbutka/ml/blob/master/L16.ipynb","timestamp":1609202114835}],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"OydShklHHtdh"},"source":["In this notebook, we'll build a model to classify online posts using a Naive Bayes classifier and a neural network.\n","\n","Below we download the online posts data from the 20newsgroups database."]},{"cell_type":"code","metadata":{"id":"tbhmnw-Ewyk7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610051824099,"user_tz":300,"elapsed":10658,"user":{"displayName":"Brian Butka","photoUrl":"","userId":"08914542393121785554"}},"outputId":"376e9afe-f90c-48e1-b265-4e78f1e3a898"},"source":["from sklearn.datasets import fetch_20newsgroups\n","newsgroups_train = fetch_20newsgroups(subset='train')\n","\n","from pprint import pprint\n","pprint(list(newsgroups_train.target_names))\n","\n"," "],"execution_count":1,"outputs":[{"output_type":"stream","text":["Downloading 20news dataset. This may take a few minutes.\n","Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"],"name":"stderr"},{"output_type":"stream","text":["['alt.atheism',\n"," 'comp.graphics',\n"," 'comp.os.ms-windows.misc',\n"," 'comp.sys.ibm.pc.hardware',\n"," 'comp.sys.mac.hardware',\n"," 'comp.windows.x',\n"," 'misc.forsale',\n"," 'rec.autos',\n"," 'rec.motorcycles',\n"," 'rec.sport.baseball',\n"," 'rec.sport.hockey',\n"," 'sci.crypt',\n"," 'sci.electronics',\n"," 'sci.med',\n"," 'sci.space',\n"," 'soc.religion.christian',\n"," 'talk.politics.guns',\n"," 'talk.politics.mideast',\n"," 'talk.politics.misc',\n"," 'talk.religion.misc']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"D2L-jQHZ4-BO"},"source":["Here is a sample of some typical text\r\n","\r\n",">Recently, RAs have been ordered (and none have resisted or cared about\r\n","> it apparently) to post a religious flyer entitled _The Soul Scroll: Thoughts\r\n","> on religion, spirituality, and matters of the soul_ on the inside of bathroom\r\n","> stall doors. (at my school, the University of New Hampshire) It is some sort\r\n","> of newsletter assembled by a Hall Director somewhere on campus. It poses a\r\n"]},{"cell_type":"markdown","metadata":{"id":"FsH7sdN_5VvM"},"source":["To limit the size of this experiment we will restrict ourselves to a few similar newsgroups.\r\n","Each of the newsgroups has data arranged in train and test directories. \r\n","Here we will train a naive Bayes classifier"]},{"cell_type":"code","metadata":{"id":"Fyst4n110jyf","executionInfo":{"status":"ok","timestamp":1610052137591,"user_tz":300,"elapsed":632,"user":{"displayName":"Brian Butka","photoUrl":"","userId":"08914542393121785554"}}},"source":["from sklearn.feature_extraction.text import TfidfVectorizer\r\n","categories = ['alt.atheism', 'talk.religion.misc',\r\n","              'comp.graphics', 'sci.space']\r\n","newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\r\n"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XxVsAv726vRW"},"source":["Next we vectorize the words in the training data and print the newsgroup names we are using as a sanity check. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kBODHOaQ6uJu","executionInfo":{"status":"ok","timestamp":1610052140194,"user_tz":300,"elapsed":959,"user":{"displayName":"Brian Butka","photoUrl":"","userId":"08914542393121785554"}},"outputId":"6ca2d1f3-4cc0-4608-9e8f-1255dc65d97e"},"source":["vectorizer = TfidfVectorizer()\r\n","vectors = vectorizer.fit_transform(newsgroups_train.data)\r\n","list(newsgroups_train.target_names)"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"jh2_LzoMllWT"},"source":["Each of the newsgroups has data arranged in train and test directories.\r\n","We will know train on the training dataset."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-fn5wyff01lj","executionInfo":{"status":"ok","timestamp":1610052176453,"user_tz":300,"elapsed":862,"user":{"displayName":"Brian Butka","photoUrl":"","userId":"08914542393121785554"}},"outputId":"020df5c4-ee25-4180-da39-28846a823909"},"source":["from sklearn.feature_extraction.text import TfidfVectorizer\r\n","from sklearn.naive_bayes import MultinomialNB\r\n","from sklearn import metrics\r\n","vectors_test = vectorizer.transform(newsgroups_train.data)\r\n","clf = MultinomialNB(alpha=.01)\r\n","clf.fit(vectors, newsgroups_train.target)\r\n","pred = clf.predict(vectors_test)\r\n","metrics.f1_score(newsgroups_train.target, pred, average='macro')\r\n"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9994081859552928"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"gtQjNNjL7RPv"},"source":["Very high accuracy on the training data. \r\n","Overfitted. \r\n","Now try the test data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qV0TY07I1asN","executionInfo":{"status":"ok","timestamp":1610052180521,"user_tz":300,"elapsed":954,"user":{"displayName":"Brian Butka","photoUrl":"","userId":"08914542393121785554"}},"outputId":"fdd3167d-81d0-45d4-b1c7-4f2187d9699e"},"source":["newsgroups_test = fetch_20newsgroups(subset='test',\r\n","                                     categories=categories)\r\n","vectors_test = vectorizer.transform(newsgroups_test.data)\r\n","pred = clf.predict(vectors_test)\r\n","metrics.f1_score(pred, newsgroups_test.target, average='macro')"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8821359240272957"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"cS15VGTb8T4o"},"source":["88% is pretty respectable, but there are issues with the data\r\n","Headers and footers contain identifying information such as email addresses\r\n","Quotes are where chains of previous posts are copied in a new post\r\n","Let's remove them and test"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kCKn5-NN7tz1","executionInfo":{"status":"ok","timestamp":1610052200478,"user_tz":300,"elapsed":1401,"user":{"displayName":"Brian Butka","photoUrl":"","userId":"08914542393121785554"}},"outputId":"4980f3ee-c6dc-473d-b1f5-6747eeff505e"},"source":["newsgroups_test = fetch_20newsgroups(subset='test',\r\n","                                     remove=('headers', 'footers', 'quotes'),\r\n","                                     categories=categories)\r\n","vectors_test = vectorizer.transform(newsgroups_test.data)\r\n","pred = clf.predict(vectors_test)\r\n","metrics.f1_score(pred, newsgroups_test.target, average='macro')"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7731035068127478"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"286v15FK8Zh1"},"source":["Definitely impacted the accuracy. Let's retrain without the headers,footers and quotes. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JEiu3L7i8lFr","executionInfo":{"status":"ok","timestamp":1610052203771,"user_tz":300,"elapsed":1758,"user":{"displayName":"Brian Butka","photoUrl":"","userId":"08914542393121785554"}},"outputId":"9002c85e-4737-4d3a-f1fc-f68e237ca807"},"source":["newsgroups_train = fetch_20newsgroups(subset='train',\r\n","                                     remove=('headers', 'footers', 'quotes'),\r\n","                                     categories=categories)\r\n","vectors_test = vectorizer.transform(newsgroups_train.data)\r\n","clf2 = MultinomialNB(alpha=.01)\r\n","clf2.fit(vectors, newsgroups_train.target)\r\n","pred = clf2.predict(vectors_test)\r\n","metrics.f1_score(newsgroups_train.target, pred, average='macro')"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9655349072873998"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"Jexgd0AK8665"},"source":["Run the test data on the new classifier"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pNDgAhoY9CUH","executionInfo":{"status":"ok","timestamp":1610052207242,"user_tz":300,"elapsed":1389,"user":{"displayName":"Brian Butka","photoUrl":"","userId":"08914542393121785554"}},"outputId":"cbf6b8d8-5688-4f60-ac4e-ab65d86ef7df"},"source":["newsgroups_test = fetch_20newsgroups(subset='test',\r\n","                                     remove=('headers', 'footers', 'quotes'),\r\n","                                     categories=categories)\r\n","vectors_test = vectorizer.transform(newsgroups_test.data)\r\n","clf2 = MultinomialNB(alpha=.01)\r\n","clf2.fit(vectors, newsgroups_train.target)\r\n","pred = clf2.predict(vectors_test)\r\n","metrics.f1_score(pred, newsgroups_test.target, average='macro')"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7731035068127478"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"t4GDNzTYIqso"},"source":["\r\n","No improvement. Now let's look it using GloVe vectors.\r\n","\r\n","Start by downloading the GloVe vectors we will be using to represent our post data. The vector set we will use is 6B200d."]},{"cell_type":"code","metadata":{"id":"sCjJULtUqjAe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610052599239,"user_tz":300,"elapsed":389276,"user":{"displayName":"Brian Butka","photoUrl":"","userId":"08914542393121785554"}},"outputId":"4ac4040f-37c8-416b-ec80-2747ceb74db6"},"source":["!wget http://nlp.stanford.edu/data/glove.6B.zip"],"execution_count":10,"outputs":[{"output_type":"stream","text":["--2021-01-07 20:43:30--  http://nlp.stanford.edu/data/glove.6B.zip\n","Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n","--2021-01-07 20:43:30--  https://nlp.stanford.edu/data/glove.6B.zip\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n","--2021-01-07 20:43:30--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n","Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n","Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 862182613 (822M) [application/zip]\n","Saving to: ‘glove.6B.zip’\n","\n","glove.6B.zip        100%[===================>] 822.24M  2.03MB/s    in 6m 28s  \n","\n","2021-01-07 20:49:59 (2.12 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GZsutIRzJCzg"},"source":["Below we unzip the GloVe file we downloaded."]},{"cell_type":"code","metadata":{"id":"5j_YyS37qv7m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609255505063,"user_tz":300,"elapsed":23856,"user":{"displayName":"Brian Butka","photoUrl":"","userId":"08914542393121785554"}},"outputId":"f7cd31ef-6ef6-40b5-fa96-f21924098a91"},"source":["!unzip glove.6B.zip"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Archive:  glove.6B.zip\n","  inflating: glove.6B.50d.txt        \n","  inflating: glove.6B.100d.txt       \n","  inflating: glove.6B.200d.txt       \n","  inflating: glove.6B.300d.txt       \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lmi-6INoJHbv"},"source":["Next, we load the GloVe vectors."]},{"cell_type":"code","metadata":{"id":"siJVA4bpyPY8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609258293059,"user_tz":300,"elapsed":9872,"user":{"displayName":"Brian Butka","photoUrl":"","userId":"08914542393121785554"}},"outputId":"11e7e3e9-0b0c-4182-f4fe-4dc43ddd35f9"},"source":["import numpy as np\n","\n","embeddings_index = {}\n","f = open('glove.6B.100d.txt')\n","for line in f:\n","    values = line.split()\n","    word = values[0]\n","    coefs = np.asarray(values[1:], dtype='float32')\n","    embeddings_index[word] = coefs\n","f.close()\n","\n","print('Found %s word vectors.' % len(embeddings_index))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 400000 word vectors.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Zzij4IlhJMsE"},"source":["Next, we convert the data to a collection of word GloVe word vectors for each of the words in our dataset."]},{"cell_type":"code","metadata":{"id":"CB7FMHUsI4WD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609258455183,"user_tz":300,"elapsed":3050,"user":{"displayName":"Brian Butka","photoUrl":"","userId":"08914542393121785554"}},"outputId":"a7cb67d4-26f2-47f4-bd5c-d6c61098c4c9"},"source":["!pip install keras=='2.3.1'\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.utils import to_categorical\n","\n","print('Preparing embedding matrix.')\n","MAX_NUM_WORDS = 20000\n","MAX_SEQUENCE_LENGTH = 1000\n","EMBEDDING_DIM = 100\n","\n","tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n","tokenizer.fit_on_texts(newsgroups_train.data)\n","sequences = tokenizer.texts_to_sequences(newsgroups_train.data)\n","\n","word_index = tokenizer.word_index\n","\n","# prepare embedding matrix\n","num_words = min(MAX_NUM_WORDS, len(word_index) + 1)\n","embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n","for word, i in word_index.items():\n","    if i >= MAX_NUM_WORDS:\n","        continue\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None:\n","        # words not found in embedding index will be all-zeros.\n","        embedding_matrix[i] = embedding_vector"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: keras==2.3.1 in /usr/local/lib/python3.6/dist-packages (2.3.1)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.1.2)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.19.4)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (2.10.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.4.1)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.15.0)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.0.8)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (3.13)\n","Preparing embedding matrix.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BuuAUWLxJqe-"},"source":["Next, we'll build our dataset for training, `data` and `labels`, as well as our test set, `data_test` and `labels_test`.  We will limit our training set to 200 examples."]},{"cell_type":"code","metadata":{"id":"71Npelu5XOXI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609258409417,"user_tz":300,"elapsed":2766,"user":{"displayName":"Brian Butka","photoUrl":"","userId":"08914542393121785554"}},"outputId":"aed36c8f-c51e-4354-a222-d9aa764bdf05"},"source":["from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","\n","# finally, vectorize the text samples into a 2D integer tensor\n","MAX_NUM_WORDS = 20000\n","MAX_SEQUENCE_LENGTH = 1000\n","\n","tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n","tokenizer.fit_on_texts(newsgroups_train.data)\n","sequences = tokenizer.texts_to_sequences(newsgroups_train.data)\n","\n","word_index = tokenizer.word_index\n","print('Found %s unique tokens.' % len(word_index))\n","\n","data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n","labels = to_categorical(np.asarray(newsgroups_train.target))\n","\n","# print(data.shape)\n","\n","data, data_test, labels, labels_test = train_test_split(data,labels,train_size=200)\n","\n","print('Shape of data tensor:', data.shape)\n","print('Shape of label tensor:', labels.shape)\n","print('Shape of data_test tensor:', data_test.shape)\n","print('Shape of label_test tensor:', labels_test.shape)\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 27471 unique tokens.\n","Shape of data tensor: (200, 1000)\n","Shape of label tensor: (200, 4)\n","Shape of data_test tensor: (1834, 1000)\n","Shape of label_test tensor: (1834, 4)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3Q80Hv4ZMM14"},"source":["Next, we'll declare a `train` function that declares and trains the model with `pretrain` weights.  "]},{"cell_type":"code","metadata":{"id":"MG5dKkuxW95S"},"source":["from tensorflow.keras.layers import Dense, Input, GlobalMaxPooling1D\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.initializers import Constant\n","# from keras.optimizers import RMSprop\n","# from keras.optimizers import Adam\n","from tensorflow.keras import optimizers\n","\n","EMBEDDING_DIM = 100\n","\n","# load pre-trained word embeddings into an Embedding layer\n","# note that we set trainable = False so as to keep the embeddings fixed\n","# num_words = len(vectorizer.vocabulary_)\n","# num_words = len(word_index)+1\n","\n","def train(pretrain):\n","  if not pretrain:  # train your own embedding\n","    embedding_layer = Embedding(num_words,\n","                              EMBEDDING_DIM,\n","                              input_length=MAX_SEQUENCE_LENGTH,\n","                              trainable=True\n","                             )\n","  else:\n","      embedding_layer = Embedding(num_words,\n","                              EMBEDDING_DIM,\n","                              embeddings_initializer=Constant(embedding_matrix),\n","                              input_length=MAX_SEQUENCE_LENGTH,\n","                              trainable=False\n","                           )\n","  print('Training model.')\n","\n","  # train a 1D convnet with global maxpooling\n","  sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n","  embedded_sequences = embedding_layer(sequence_input)\n","  x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n","  x = MaxPooling1D(5)(x)\n","  x = Conv1D(128, 5, activation='relu')(x)\n","  x = MaxPooling1D(5)(x)\n","  x = Conv1D(128, 5, activation='relu')(x)\n","  x = GlobalMaxPooling1D()(x)\n","  x = Dense(128, activation='relu')(x)\n","  preds = Dense(len(categories), activation='softmax')(x)\n","\n","  solver = optimizers.Adam(lr=0.0005)\n","\n","  model = Model(sequence_input, preds)\n","  model.compile(loss='categorical_crossentropy',\n","                optimizer=solver,\n","                metrics=['acc'])\n","\n","  model.fit(data, labels,\n","            epochs=50,\n","            validation_data=(data_test, labels_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qv-pPgvvRFPs"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1Ufl-EMEMn7L"},"source":["Below we train the model without pretrained weights."]},{"cell_type":"code","metadata":{"id":"cBFzGzyqXKGk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609259325983,"user_tz":300,"elapsed":29626,"user":{"displayName":"Brian Butka","photoUrl":"","userId":"08914542393121785554"}},"outputId":"8e8f413a-a963-4751-e68c-47dd3fee2258"},"source":["train(False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training model.\n","Epoch 1/50\n","7/7 [==============================] - 1s 133ms/step - loss: 1.3850 - acc: 0.2864 - val_loss: 1.3814 - val_acc: 0.2328\n","Epoch 2/50\n","7/7 [==============================] - 1s 89ms/step - loss: 1.3652 - acc: 0.2505 - val_loss: 1.3803 - val_acc: 0.2704\n","Epoch 3/50\n","7/7 [==============================] - 1s 87ms/step - loss: 1.3393 - acc: 0.3250 - val_loss: 1.3859 - val_acc: 0.2606\n","Epoch 4/50\n","7/7 [==============================] - 1s 86ms/step - loss: 1.3232 - acc: 0.3336 - val_loss: 1.3782 - val_acc: 0.2797\n","Epoch 5/50\n","7/7 [==============================] - 1s 90ms/step - loss: 1.3059 - acc: 0.4335 - val_loss: 1.3784 - val_acc: 0.2721\n","Epoch 6/50\n","7/7 [==============================] - 1s 88ms/step - loss: 1.2969 - acc: 0.3686 - val_loss: 1.3872 - val_acc: 0.2710\n","Epoch 7/50\n","7/7 [==============================] - 1s 85ms/step - loss: 1.2581 - acc: 0.3808 - val_loss: 1.3861 - val_acc: 0.2721\n","Epoch 8/50\n","7/7 [==============================] - 1s 88ms/step - loss: 1.2376 - acc: 0.4621 - val_loss: 1.3721 - val_acc: 0.2721\n","Epoch 9/50\n","7/7 [==============================] - 1s 88ms/step - loss: 1.1950 - acc: 0.5746 - val_loss: 1.3780 - val_acc: 0.2748\n","Epoch 10/50\n","7/7 [==============================] - 1s 87ms/step - loss: 1.1134 - acc: 0.5372 - val_loss: 1.3549 - val_acc: 0.3075\n","Epoch 11/50\n","7/7 [==============================] - 1s 85ms/step - loss: 1.0491 - acc: 0.6562 - val_loss: 1.3425 - val_acc: 0.3141\n","Epoch 12/50\n","7/7 [==============================] - 1s 89ms/step - loss: 0.9396 - acc: 0.6846 - val_loss: 1.3367 - val_acc: 0.3588\n","Epoch 13/50\n","7/7 [==============================] - 1s 110ms/step - loss: 0.8384 - acc: 0.6896 - val_loss: 1.2396 - val_acc: 0.4378\n","Epoch 14/50\n","7/7 [==============================] - 1s 85ms/step - loss: 0.6503 - acc: 0.8946 - val_loss: 1.2663 - val_acc: 0.3931\n","Epoch 15/50\n","7/7 [==============================] - 1s 89ms/step - loss: 0.5127 - acc: 0.8203 - val_loss: 1.1722 - val_acc: 0.4646\n","Epoch 16/50\n","7/7 [==============================] - 1s 88ms/step - loss: 0.3690 - acc: 0.9625 - val_loss: 1.1344 - val_acc: 0.4580\n","Epoch 17/50\n","7/7 [==============================] - 1s 87ms/step - loss: 0.3106 - acc: 0.9286 - val_loss: 1.1544 - val_acc: 0.4858\n","Epoch 18/50\n","7/7 [==============================] - 1s 89ms/step - loss: 0.2121 - acc: 0.9707 - val_loss: 1.0253 - val_acc: 0.5485\n","Epoch 19/50\n","7/7 [==============================] - 1s 88ms/step - loss: 0.1454 - acc: 0.9694 - val_loss: 1.0721 - val_acc: 0.5463\n","Epoch 20/50\n","7/7 [==============================] - 1s 86ms/step - loss: 0.1267 - acc: 0.9755 - val_loss: 1.0813 - val_acc: 0.5425\n","Epoch 21/50\n","7/7 [==============================] - 1s 88ms/step - loss: 0.1095 - acc: 0.9681 - val_loss: 1.0451 - val_acc: 0.5523\n","Epoch 22/50\n","7/7 [==============================] - 1s 88ms/step - loss: 0.0931 - acc: 0.9676 - val_loss: 1.0091 - val_acc: 0.5654\n","Epoch 23/50\n","7/7 [==============================] - 1s 87ms/step - loss: 0.1146 - acc: 0.9655 - val_loss: 0.9904 - val_acc: 0.5872\n","Epoch 24/50\n","7/7 [==============================] - 1s 90ms/step - loss: 0.1001 - acc: 0.9708 - val_loss: 1.0600 - val_acc: 0.5649\n","Epoch 25/50\n","7/7 [==============================] - 1s 85ms/step - loss: 0.0686 - acc: 0.9814 - val_loss: 1.1171 - val_acc: 0.5403\n","Epoch 26/50\n","7/7 [==============================] - 1s 88ms/step - loss: 0.1052 - acc: 0.9640 - val_loss: 1.1009 - val_acc: 0.5458\n","Epoch 27/50\n","7/7 [==============================] - 1s 86ms/step - loss: 0.0800 - acc: 0.9699 - val_loss: 1.0482 - val_acc: 0.5709\n","Epoch 28/50\n","7/7 [==============================] - 1s 89ms/step - loss: 0.0639 - acc: 0.9788 - val_loss: 1.0171 - val_acc: 0.5812\n","Epoch 29/50\n","7/7 [==============================] - 1s 88ms/step - loss: 0.0636 - acc: 0.9790 - val_loss: 1.0149 - val_acc: 0.5845\n","Epoch 30/50\n","7/7 [==============================] - 1s 89ms/step - loss: 0.0473 - acc: 0.9834 - val_loss: 1.0868 - val_acc: 0.5769\n","Epoch 31/50\n","7/7 [==============================] - 1s 86ms/step - loss: 0.0948 - acc: 0.9622 - val_loss: 1.1294 - val_acc: 0.5589\n","Epoch 32/50\n","7/7 [==============================] - 1s 88ms/step - loss: 0.0864 - acc: 0.9617 - val_loss: 1.0759 - val_acc: 0.5660\n","Epoch 33/50\n","7/7 [==============================] - 1s 91ms/step - loss: 0.0670 - acc: 0.9741 - val_loss: 1.0714 - val_acc: 0.5616\n","Epoch 34/50\n","7/7 [==============================] - 1s 87ms/step - loss: 0.0764 - acc: 0.9682 - val_loss: 1.0571 - val_acc: 0.5714\n","Epoch 35/50\n","7/7 [==============================] - 1s 90ms/step - loss: 0.0780 - acc: 0.9695 - val_loss: 1.0409 - val_acc: 0.5796\n","Epoch 36/50\n","7/7 [==============================] - 1s 87ms/step - loss: 0.1055 - acc: 0.9540 - val_loss: 1.0403 - val_acc: 0.5851\n","Epoch 37/50\n","7/7 [==============================] - 1s 106ms/step - loss: 0.0781 - acc: 0.9686 - val_loss: 1.0597 - val_acc: 0.5752\n","Epoch 38/50\n","7/7 [==============================] - 1s 86ms/step - loss: 0.0606 - acc: 0.9769 - val_loss: 1.0893 - val_acc: 0.5654\n","Epoch 39/50\n","7/7 [==============================] - 1s 89ms/step - loss: 0.0907 - acc: 0.9599 - val_loss: 1.0464 - val_acc: 0.5763\n","Epoch 40/50\n","7/7 [==============================] - 1s 88ms/step - loss: 0.0871 - acc: 0.9673 - val_loss: 1.0479 - val_acc: 0.5791\n","Epoch 41/50\n","7/7 [==============================] - 1s 86ms/step - loss: 0.0776 - acc: 0.9700 - val_loss: 1.0897 - val_acc: 0.5698\n","Epoch 42/50\n","7/7 [==============================] - 1s 89ms/step - loss: 0.0541 - acc: 0.9803 - val_loss: 1.1272 - val_acc: 0.5605\n","Epoch 43/50\n","7/7 [==============================] - 1s 88ms/step - loss: 0.0903 - acc: 0.9631 - val_loss: 1.1604 - val_acc: 0.5573\n","Epoch 44/50\n","7/7 [==============================] - 1s 89ms/step - loss: 0.0757 - acc: 0.9700 - val_loss: 1.1270 - val_acc: 0.5622\n","Epoch 45/50\n","7/7 [==============================] - 1s 87ms/step - loss: 0.0484 - acc: 0.9835 - val_loss: 1.1217 - val_acc: 0.5643\n","Epoch 46/50\n","7/7 [==============================] - 1s 89ms/step - loss: 0.0646 - acc: 0.9773 - val_loss: 1.1419 - val_acc: 0.5654\n","Epoch 47/50\n","7/7 [==============================] - 1s 88ms/step - loss: 0.0880 - acc: 0.9603 - val_loss: 1.1443 - val_acc: 0.5687\n","Epoch 48/50\n","7/7 [==============================] - 1s 89ms/step - loss: 0.0946 - acc: 0.9614 - val_loss: 1.1383 - val_acc: 0.5709\n","Epoch 49/50\n","7/7 [==============================] - 1s 88ms/step - loss: 0.0587 - acc: 0.9767 - val_loss: 1.1114 - val_acc: 0.5747\n","Epoch 50/50\n","7/7 [==============================] - 1s 86ms/step - loss: 0.0702 - acc: 0.9778 - val_loss: 1.0606 - val_acc: 0.5829\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wFgJVqEjMsaR"},"source":["Next we train the model with pretrained weights."]},{"cell_type":"code","metadata":{"id":"Ni_xRrAmdN-X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609259465245,"user_tz":300,"elapsed":23454,"user":{"displayName":"Brian Butka","photoUrl":"","userId":"08914542393121785554"}},"outputId":"42b60cd5-92c6-439e-bd5a-00393a2958d3"},"source":["train(True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training model.\n","Epoch 1/50\n","7/7 [==============================] - 1s 114ms/step - loss: 1.4126 - acc: 0.2621 - val_loss: 1.3461 - val_acc: 0.3201\n","Epoch 2/50\n","7/7 [==============================] - 0s 68ms/step - loss: 1.2972 - acc: 0.4096 - val_loss: 1.3328 - val_acc: 0.3342\n","Epoch 3/50\n","7/7 [==============================] - 0s 65ms/step - loss: 1.2425 - acc: 0.4370 - val_loss: 1.3033 - val_acc: 0.3244\n","Epoch 4/50\n","7/7 [==============================] - 0s 69ms/step - loss: 1.1717 - acc: 0.3959 - val_loss: 1.2655 - val_acc: 0.3795\n","Epoch 5/50\n","7/7 [==============================] - 0s 67ms/step - loss: 1.0642 - acc: 0.5856 - val_loss: 1.2269 - val_acc: 0.3621\n","Epoch 6/50\n","7/7 [==============================] - 0s 68ms/step - loss: 0.9841 - acc: 0.5812 - val_loss: 1.1277 - val_acc: 0.5109\n","Epoch 7/50\n","7/7 [==============================] - 1s 91ms/step - loss: 0.8213 - acc: 0.7598 - val_loss: 1.0383 - val_acc: 0.5573\n","Epoch 8/50\n","7/7 [==============================] - 0s 69ms/step - loss: 0.6529 - acc: 0.8185 - val_loss: 0.9757 - val_acc: 0.5638\n","Epoch 9/50\n","7/7 [==============================] - 0s 68ms/step - loss: 0.5557 - acc: 0.8934 - val_loss: 0.9334 - val_acc: 0.5889\n","Epoch 10/50\n","7/7 [==============================] - 0s 69ms/step - loss: 0.4446 - acc: 0.9110 - val_loss: 0.9028 - val_acc: 0.6041\n","Epoch 11/50\n","7/7 [==============================] - 0s 70ms/step - loss: 0.4308 - acc: 0.9415 - val_loss: 1.0017 - val_acc: 0.5889\n","Epoch 12/50\n","7/7 [==============================] - 0s 71ms/step - loss: 0.3350 - acc: 0.9204 - val_loss: 0.9765 - val_acc: 0.5523\n","Epoch 13/50\n","7/7 [==============================] - 0s 75ms/step - loss: 0.2726 - acc: 0.9595 - val_loss: 0.8478 - val_acc: 0.6118\n","Epoch 14/50\n","7/7 [==============================] - 0s 73ms/step - loss: 0.2089 - acc: 0.9611 - val_loss: 0.8685 - val_acc: 0.6358\n","Epoch 15/50\n","7/7 [==============================] - 0s 72ms/step - loss: 0.1985 - acc: 0.9609 - val_loss: 1.1281 - val_acc: 0.5807\n","Epoch 16/50\n","7/7 [==============================] - 0s 70ms/step - loss: 0.1590 - acc: 0.9540 - val_loss: 0.9209 - val_acc: 0.6303\n","Epoch 17/50\n","7/7 [==============================] - 0s 73ms/step - loss: 0.1620 - acc: 0.9712 - val_loss: 0.9588 - val_acc: 0.6031\n","Epoch 18/50\n","7/7 [==============================] - 0s 72ms/step - loss: 0.1323 - acc: 0.9668 - val_loss: 0.8875 - val_acc: 0.6336\n","Epoch 19/50\n","7/7 [==============================] - 0s 74ms/step - loss: 0.1158 - acc: 0.9711 - val_loss: 1.0394 - val_acc: 0.6118\n","Epoch 20/50\n","7/7 [==============================] - 0s 71ms/step - loss: 0.1042 - acc: 0.9673 - val_loss: 0.9562 - val_acc: 0.6003\n","Epoch 21/50\n","7/7 [==============================] - 0s 72ms/step - loss: 0.1019 - acc: 0.9635 - val_loss: 1.0735 - val_acc: 0.6189\n","Epoch 22/50\n","7/7 [==============================] - 0s 73ms/step - loss: 0.0881 - acc: 0.9743 - val_loss: 1.0015 - val_acc: 0.6227\n","Epoch 23/50\n","7/7 [==============================] - 0s 71ms/step - loss: 0.0932 - acc: 0.9780 - val_loss: 1.0696 - val_acc: 0.6167\n","Epoch 24/50\n","7/7 [==============================] - 0s 72ms/step - loss: 0.0741 - acc: 0.9764 - val_loss: 1.0127 - val_acc: 0.6161\n","Epoch 25/50\n","7/7 [==============================] - 0s 72ms/step - loss: 0.0928 - acc: 0.9621 - val_loss: 1.0643 - val_acc: 0.6303\n","Epoch 26/50\n","7/7 [==============================] - 0s 72ms/step - loss: 0.0797 - acc: 0.9670 - val_loss: 1.0532 - val_acc: 0.6270\n","Epoch 27/50\n","7/7 [==============================] - 0s 71ms/step - loss: 0.0982 - acc: 0.9611 - val_loss: 1.1131 - val_acc: 0.6194\n","Epoch 28/50\n","7/7 [==============================] - 0s 71ms/step - loss: 0.0627 - acc: 0.9748 - val_loss: 1.0903 - val_acc: 0.6303\n","Epoch 29/50\n","7/7 [==============================] - 0s 71ms/step - loss: 0.0879 - acc: 0.9735 - val_loss: 1.0892 - val_acc: 0.6298\n","Epoch 30/50\n","7/7 [==============================] - 0s 71ms/step - loss: 0.0735 - acc: 0.9663 - val_loss: 1.1094 - val_acc: 0.6265\n","Epoch 31/50\n","7/7 [==============================] - 0s 72ms/step - loss: 0.0832 - acc: 0.9776 - val_loss: 1.1237 - val_acc: 0.6303\n","Epoch 32/50\n","7/7 [==============================] - 1s 92ms/step - loss: 0.1026 - acc: 0.9628 - val_loss: 1.1263 - val_acc: 0.6303\n","Epoch 33/50\n","7/7 [==============================] - 0s 72ms/step - loss: 0.0653 - acc: 0.9815 - val_loss: 1.1159 - val_acc: 0.6330\n","Epoch 34/50\n","7/7 [==============================] - 0s 70ms/step - loss: 0.0790 - acc: 0.9701 - val_loss: 1.1689 - val_acc: 0.6210\n","Epoch 35/50\n","7/7 [==============================] - 0s 70ms/step - loss: 0.0463 - acc: 0.9881 - val_loss: 1.1295 - val_acc: 0.6265\n","Epoch 36/50\n","7/7 [==============================] - 0s 68ms/step - loss: 0.0738 - acc: 0.9762 - val_loss: 1.2150 - val_acc: 0.6156\n","Epoch 37/50\n","7/7 [==============================] - 0s 69ms/step - loss: 0.0816 - acc: 0.9758 - val_loss: 1.1768 - val_acc: 0.6309\n","Epoch 38/50\n","7/7 [==============================] - 0s 68ms/step - loss: 0.1042 - acc: 0.9589 - val_loss: 1.1478 - val_acc: 0.6325\n","Epoch 39/50\n","7/7 [==============================] - 0s 68ms/step - loss: 0.0522 - acc: 0.9839 - val_loss: 1.2380 - val_acc: 0.6292\n","Epoch 40/50\n","7/7 [==============================] - 0s 69ms/step - loss: 0.0607 - acc: 0.9697 - val_loss: 1.1702 - val_acc: 0.6363\n","Epoch 41/50\n","7/7 [==============================] - 0s 68ms/step - loss: 0.0662 - acc: 0.9750 - val_loss: 1.1758 - val_acc: 0.6265\n","Epoch 42/50\n","7/7 [==============================] - 0s 69ms/step - loss: 0.0732 - acc: 0.9708 - val_loss: 1.2684 - val_acc: 0.6200\n","Epoch 43/50\n","7/7 [==============================] - 0s 69ms/step - loss: 0.0720 - acc: 0.9658 - val_loss: 1.2304 - val_acc: 0.6265\n","Epoch 44/50\n","7/7 [==============================] - 0s 69ms/step - loss: 0.0687 - acc: 0.9710 - val_loss: 1.1995 - val_acc: 0.6390\n","Epoch 45/50\n","7/7 [==============================] - 0s 68ms/step - loss: 0.0567 - acc: 0.9781 - val_loss: 1.2782 - val_acc: 0.6254\n","Epoch 46/50\n","7/7 [==============================] - 0s 68ms/step - loss: 0.0420 - acc: 0.9887 - val_loss: 1.2300 - val_acc: 0.6358\n","Epoch 47/50\n","7/7 [==============================] - 0s 69ms/step - loss: 0.0912 - acc: 0.9615 - val_loss: 1.2683 - val_acc: 0.6347\n","Epoch 48/50\n","7/7 [==============================] - 0s 67ms/step - loss: 0.0643 - acc: 0.9783 - val_loss: 1.2374 - val_acc: 0.6320\n","Epoch 49/50\n","7/7 [==============================] - 0s 70ms/step - loss: 0.0477 - acc: 0.9833 - val_loss: 1.3147 - val_acc: 0.6243\n","Epoch 50/50\n","7/7 [==============================] - 0s 67ms/step - loss: 0.0648 - acc: 0.9753 - val_loss: 1.2413 - val_acc: 0.6303\n"],"name":"stdout"}]}]}