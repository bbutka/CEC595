{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"8b_Language_Output.ipynb","provenance":[{"file_id":"https://github.com/bbutka/ml/blob/master/L17.ipynb","timestamp":1609277188551}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"eDEziJFNRShb"},"source":["Letâ€™s write some python code to use all four of the released models for generating text. That will let us see how the changes in capacity related to the quality of the text produced.\n","\n","We download the GPT-2 library from OpenAI.\n","\n","The OpenAI codebase has a list of other libraries that it requires, which is handled by installing requirements.txt. We go to the appropriate file, requirements.txt, and install those libraries.\n","\n","Then, we download four different pre-trained models OpenAI made available, each roughly double in size from the previous."]},{"cell_type":"code","metadata":{"id":"bHr2nt3-ktjE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610055932006,"user_tz":300,"elapsed":453854,"user":{"displayName":"Brian Butka","photoUrl":"","userId":"08914542393121785554"}},"outputId":"507923a2-840f-418d-e516-c15f5f1b767b"},"source":["!git clone https://github.com/openai/gpt-2.git\n","import os\n","os.chdir(\"gpt-2\")\n","import warnings\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n","warnings.filterwarnings('ignore')\n","%tensorflow_version 1.x\n","!pip3 install -r requirements.txt\n","!python3 download_model.py 124M\n","!python3 download_model.py 345M\n","!python3 download_model.py 774M\n","!python3 download_model.py 1558M"],"execution_count":2,"outputs":[{"output_type":"stream","text":["fatal: destination path 'gpt-2' already exists and is not an empty directory.\n","TensorFlow 1.x selected.\n","Requirement already satisfied: fire>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (0.3.1)\n","Requirement already satisfied: regex==2017.4.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (2017.4.5)\n","Requirement already satisfied: requests==2.21.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (2.21.0)\n","Requirement already satisfied: tqdm==4.31.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (4.31.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.15.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.1.0)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2.8)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2020.12.5)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (3.0.4)\n","Fetching checkpoint: 1.00kit [00:00, 824kit/s]                                                      \n","Fetching encoder.json: 1.04Mit [00:00, 2.90Mit/s]                                                   \n","Fetching hparams.json: 1.00kit [00:00, 838kit/s]                                                    \n","Fetching model.ckpt.data-00000-of-00001: 498Mit [00:17, 27.7Mit/s]                                  \n","Fetching model.ckpt.index: 6.00kit [00:00, 4.54Mit/s]                                               \n","Fetching model.ckpt.meta: 472kit [00:00, 1.65Mit/s]                                                 \n","Fetching vocab.bpe: 457kit [00:00, 1.76Mit/s]                                                       \n","Fetching checkpoint: 1.00kit [00:00, 797kit/s]                                                      \n","Fetching encoder.json: 1.04Mit [00:00, 3.18Mit/s]                                                   \n","Fetching hparams.json: 1.00kit [00:00, 797kit/s]                                                    \n","Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:44, 31.9Mit/s]                                 \n","Fetching model.ckpt.index: 11.0kit [00:00, 8.19Mit/s]                                               \n","Fetching model.ckpt.meta: 927kit [00:00, 2.56Mit/s]                                                 \n","Fetching vocab.bpe: 457kit [00:00, 2.02Mit/s]                                                       \n","Fetching checkpoint: 1.00kit [00:00, 809kit/s]                                                      \n","Fetching encoder.json: 1.04Mit [00:00, 2.87Mit/s]                                                   \n","Fetching hparams.json: 1.00kit [00:00, 856kit/s]                                                    \n","Fetching model.ckpt.data-00000-of-00001: 3.10Git [01:18, 39.5Mit/s]                                 \n","Fetching model.ckpt.index: 16.0kit [00:00, 8.37Mit/s]                                               \n","Fetching model.ckpt.meta: 1.38Mit [00:00, 3.21Mit/s]                                                \n","Fetching vocab.bpe: 457kit [00:00, 1.74Mit/s]                                                       \n","Fetching checkpoint: 1.00kit [00:00, 645kit/s]                                                      \n","Fetching encoder.json: 1.04Mit [00:00, 2.87Mit/s]                                                   \n","Fetching hparams.json: 1.00kit [00:00, 689kit/s]                                                    \n","Fetching model.ckpt.data-00000-of-00001: 6.23Git [04:58, 20.9Mit/s]                                 \n","Fetching model.ckpt.index: 21.0kit [00:00, 582kit/s]                                                \n","Fetching model.ckpt.meta: 1.84Mit [00:00, 3.47Mit/s]                                                \n","Fetching vocab.bpe: 457kit [00:00, 1.51Mit/s]                                                       \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"N2ulVIo6RWv_"},"source":["Next we import some addtional libraries we'll be using in this notebook."]},{"cell_type":"code","metadata":{"id":"kgBnwO6w1WCd","executionInfo":{"status":"ok","timestamp":1610057313113,"user_tz":300,"elapsed":480,"user":{"displayName":"Brian Butka","photoUrl":"","userId":"08914542393121785554"}}},"source":["import tensorflow.compat.v1 as tf\r\n","tf.disable_v2_behavior()\r\n"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MTFrok1ARZyz"},"source":["We define an `autocomplete` function that returns the next `length` number of words given the `model_name` and the `raw_text` input.\n","\n","We set up a session for talking to the tensorflow backend. We also create a place for the output of the model to go. We checkpoint the tensorflow backend so we can establish the link to our code.Once all of that is set up, we can send our text prompt to the model for processing. We pull out the output of the model and return the string."]},{"cell_type":"code","metadata":{"id":"Uckub33ZlOTR","executionInfo":{"status":"ok","timestamp":1610057318723,"user_tz":300,"elapsed":465,"user":{"displayName":"Brian Butka","photoUrl":"","userId":"08914542393121785554"}}},"source":["# Return-a-string version\n","\n","def autocomplete(model_name, raw_text, length):\n","    batch_size = 1\n","    temperature = 1\n","    top_k = 0\n","    models_dir = '../models'\n","    seed = None\n","    models_dir = os.path.expanduser(os.path.expandvars(models_dir))\n","\n","    enc = encoder.get_encoder(model_name, models_dir)\n","    hparams = model.default_hparams()\n","    with open(os.path.join(models_dir, model_name, 'hparams.json')) as f:\n","        hparams.override_from_dict(json.load(f))\n","\n","    if length > hparams.n_ctx:\n","        raise ValueError(\"Can't get samples longer than window size: %s\" % hparams.n_ctx)\n","\n","    with tf.Session(graph=tf.Graph()) as sess:\n","        context = tf.placeholder(tf.int32, [batch_size, None])\n","        np.random.seed(seed)\n","        tf.set_random_seed(seed)\n","        output = sample.sample_sequence(\n","            hparams=hparams, length=length,\n","            context=context,\n","            batch_size=batch_size,\n","            temperature=temperature, top_k=top_k\n","        )\n","\n","        saver = tf.train.Saver()\n","        ckpt = tf.train.latest_checkpoint(os.path.join(models_dir, model_name))\n","        saver.restore(sess, ckpt)\n","\n","        context_tokens = enc.encode(raw_text)\n","        out = sess.run(output, feed_dict={\n","                context: [context_tokens]\n","        })[:, len(context_tokens):]\n","        text = enc.decode(out[0])\n","    return(text)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vUrae7LcRd3z"},"source":["Below is an example of our `autocomplete` function, printing out the next 10 predicted words."]},{"cell_type":"code","metadata":{"id":"olLMrz6plc1n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610057340015,"user_tz":300,"elapsed":18439,"user":{"displayName":"Brian Butka","photoUrl":"","userId":"08914542393121785554"}},"outputId":"f573c2c2-8706-4768-df87-67f15a68e120"},"source":["print(autocomplete('124M', \"Learning about machine learning is kind of like\", 10))"],"execution_count":15,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /content/gpt-2/src/sample.py:51: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n","\n","WARNING:tensorflow:From /content/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /content/gpt-2/src/model.py:152: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n","\n","WARNING:tensorflow:From /content/gpt-2/src/model.py:36: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n","\n","WARNING:tensorflow:From /content/gpt-2/src/sample.py:64: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:From /content/gpt-2/src/sample.py:39: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/gpt-2/src/sample.py:67: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.random.categorical` instead.\n","INFO:tensorflow:Restoring parameters from ../models/124M/model.ckpt\n"," getting out of bed and coding professionally. You just\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZPKhoX45Rin_"},"source":["Here show how the predictions for a given phrase changes with the number of parameters in the model."]},{"cell_type":"code","metadata":{"id":"GGeP35JUlb6N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610057664421,"user_tz":300,"elapsed":297583,"user":{"displayName":"Brian Butka","photoUrl":"","userId":"08914542393121785554"}},"outputId":"02671ed9-d7cc-4b7d-e76f-083773bedc94"},"source":["for gpt2model in ['124M', '345M', '774M', '1558M']:\n","  print(gpt2model, autocomplete(gpt2model, \"My first time visiting the ocean, I marveled at\", 20))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from ../models/124M/model.ckpt\n","124M  lounging in the land of Lake Chad (a portage that left little steam), which was\n","INFO:tensorflow:Restoring parameters from ../models/345M/model.ckpt\n","345M  what felt like all the riches I had missed out on in outdoor recreation. The Gulf of Aden seemed\n","INFO:tensorflow:Restoring parameters from ../models/774M/model.ckpt\n","774M  the hot view and expected that the tsunami, which was fledged from the sea about several days earlier\n","INFO:tensorflow:Restoring parameters from ../models/1558M/model.ckpt\n","1558M  the beauty and scope of the world, tried to conjure it with words from the books of my\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"f6npCZsBTbrw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610058082879,"user_tz":300,"elapsed":290790,"user":{"displayName":"Brian Butka","photoUrl":"","userId":"08914542393121785554"}},"outputId":"e824e03e-354d-411b-8cb1-efde46fe0c7c"},"source":["for gpt2model in ['124M', '345M', '774M', '1558M']:\r\n","  print(gpt2model, autocomplete(gpt2model, \"When I first arrived at college, I could not believe\", 20))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from ../models/124M/model.ckpt\n","124M  that the word \"pedophile\" would come around these days, but, at the time, I\n","INFO:tensorflow:Restoring parameters from ../models/345M/model.ckpt\n","345M  all this awesome students went to college, but looked upon their degree as not relevant anymore. This realization\n","INFO:tensorflow:Restoring parameters from ../models/774M/model.ckpt\n","774M  no one read Sorcery! It was so strange. It actually was quite top secret.\n","\n","\n","INFO:tensorflow:Restoring parameters from ../models/1558M/model.ckpt\n","1558M  how many boys wanted to kiss me. When I saw it on TV or in books, I laughed\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9MJWPH-jVTHT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610058467914,"user_tz":300,"elapsed":271500,"user":{"displayName":"Brian Butka","photoUrl":"","userId":"08914542393121785554"}},"outputId":"41869b91-aba2-4257-d7da-c3817604f8f3"},"source":["for gpt2model in ['124M', '345M', '774M', '1558M']:\r\n","  print(gpt2model, autocomplete(gpt2model, \"The color of broccoli is a deep\", 1))"],"execution_count":19,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from ../models/124M/model.ckpt\n","124M  red\n","INFO:tensorflow:Restoring parameters from ../models/345M/model.ckpt\n","345M ,\n","INFO:tensorflow:Restoring parameters from ../models/774M/model.ckpt\n","774M  shade\n","INFO:tensorflow:Restoring parameters from ../models/1558M/model.ckpt\n","1558M ,\n"],"name":"stdout"}]}]}